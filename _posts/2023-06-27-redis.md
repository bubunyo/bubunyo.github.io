---
layout: post
title: "Redis"
description: "Why is redis fast, what are the pros and cons of using redis"
comments: true
keywords: "redis, infrastructure"
published: false
---

[Redis](https://redis.io) is often touted as a pargaon of perforamce and rightly so, benchmarking for redis compared to other persistence stacks is unrivalled. 
Redis was designed to be a blazingly fast key value store to make caching easy. And for most parts it lives up to the billing. Setting up and using redis has always been a breeze.  The success of redis has made it it a very powerful tool in the software engineers arsenal of tools, with its support of almost any data type and associated operations out of the box, it is a perfect solution for the persistence of any data type; almost. As with everything else, people have used it in ways without consideration for if its fitness for the problem at hand often to great success.

Redis is famed for being able to perform most O(1) operations that is measured in sub milliseconds. And the key to this is how it is designed. 
It is designed to store data in memory. If your first year computer science class is anything to go by, you will know this provides much fast read and write throughput  compared to disk by miles. It takes advantage of the underlying data structures that are optimized for in memory storage without worrying about how to persist it to durable storage. .It is also single threaded, Though a performant single thread system might sound counter intuitive, that are some peculiar performant advantages to it. And redis takes advantage of this in a brilliant way to ensure consistency without an cost to performance. Redis's single-thread will scales indefinitely in terms of I/O concurrency. It does this by using an I/O demultiplexing mechanism and a concise event loop designed by the author. Thus there is no synchronization to be done since all commands are serialized. It might look like CPU might become a bottle neck with this design but it turns out more often than not, you will hit a network bottleneck well before CPU cannot keep up. The positive side effect of this design is that atomicity of all operations come at no extra cost. Redis also use a [proprietary protocol](https://redis.io/docs/reference/protocol-spec/), that is much more terse.  Couple the isolated event loop with a proprietary communication protocol and you have a blazing fast in memory data store that scales indefinitely in theory. 
 
These facts only holds when the size of your payload and the number of connections remain relatively small. this easily jumps out the window with ever increasing load parameters. The threshold is unfortunately rather low at a high number connections and increased payload sizes. Modern large scale micro-services will easily have over 100 running instance at medium scale. And since most instances employing some pooling mechanism to so as not to pay a connection cost for each request, A single redis instance is going to a bit of work in maintaining those connections not to talk of serving requests as they come through. To improve performance at medium to high loads, some projects such as KeyDb which is supposed to be a drop in replacement for redis employs multithreaded approach and a bit of magic to sustain some high workloads. This has been touted to provide 5x performance over redis. Another solution which I have seen used is to employ a proxy that multiplexes over multiple redises. One such proxy is the twoemproxy developed at twitter. Twoemproxy is in itself single threaded and employs key hashing to store keys in shards of multiple redis instance give you proper multiplixing. While it may look like this is susceptible to the original problems of a single threaded application, it is not necessarily the reality, because twoemproxy employs a single thread for each redis instance, turning the whole system into a multi threaded systems. Of course this is still susceptible to hotkeys. These might look like ideal solutions, setting up new infrastructure as an intermediary service introduces a new failure point and this is neither trivial nor ideal. But when done, there is a lot of net positives. 

Another major concern with redis is durability of data. Redis out of the box does not persist data on disk, only in memory. This means, when a server goes up, so does all you data. Durability is serious business and when it starts to become a priority, redis goes backwards. Redis was never planned to be provide durable beyond RAM. This is evident in the fact that disk persistence, was never part of redis until, v 0.04. And even with that the two persistence options available; snapshotting and AOF, leave much to be desired. 

### Why redis is fast


### Pros, Cons?

### Should you use redis?
